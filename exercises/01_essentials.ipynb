{"cells":[{"cell_type":"markdown","metadata":{"id":"vCrEmr0S6bRa"},"source":["# GENERAL COMMANDS"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yw_Cat_E6bRd"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import time\n","\n","from sklearn import preprocessing\n","\n","from sklearn.preprocessing import Normalizer\n","from sklearn.decomposition import PCA\n","from sklearn.feature_selection import SelectKBest, RFE\n","\n","#classification\n","from sklearn.svm import SVC\n","from sklearn.svm import LinearSVC\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.naive_bayes import MultinomialNB\n","\n","#regression\n","from sklearn.svm import LinearSVR\n","from sklearn.svm import SVR\n","from sklearn.neighbors import KNeighborsRegressor\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.linear_model import LinearRegression\n","from sklearn.linear_model import Ridge #least squares\n","from sklearn.linear_model import Lasso\n","from sklearn.ensemble import AdaBoostRegressor\n","from sklearn.ensemble import RandomForestRegressor\n","\n","from sklearn.metrics import confusion_matrix, classificiation_report, accuracy_score, plot_confusion_matrix\n","from sklearn.model_selection import cross_val_score, train_test_split\n","\n","%matplotlib inline"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9jTlvX3l6bRe"},"outputs":[],"source":["data = pd.read_csv('weather.csv', sep=';')"]},{"cell_type":"markdown","metadata":{"id":"u1H_02gp6bRe"},"source":["DATA VISUALIZATION"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ouMe4CfY6bRe"},"outputs":[],"source":["# Count instances\n","data.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jUMIIIon6bRf"},"outputs":[],"source":["# List of columns names\n","data.columns"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1BVTHxw46bRf"},"outputs":[],"source":["# Dataset description\n","data.describe()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yGMxldBG6bRf"},"outputs":[],"source":["# Show dtype for each column\n","data.dtypes"]},{"cell_type":"code","source":["# Info about dataset\n","data.info"],"metadata":{"id":"16jbu9IG970G"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rtlSXkTB6bRg"},"outputs":[],"source":["# Check for nan values\n","data[data.isna().any(axis=1)]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZzU1Kfr_6bRg"},"outputs":[],"source":["# Check for all zeros columns\n","data.columns[(data == 0).all()]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3E5ux5uG6bRg"},"outputs":[],"source":["# Dataset bilanciato 50:50\n","data.groupby('y').size().plot(kind='bar')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0gzl4bnz6bRh"},"outputs":[],"source":["# Visualize one column distribution\n","data.groupby('age').size().plot()\n","plt.show()"]},{"cell_type":"code","source":["# Features histogram\n","data.hist(figsize(12,12))\n","plt.show()"],"metadata":{"id":"aHnwKlU9B87X"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cnXS9NqW6bRh"},"outputs":[],"source":["# Counting rows for each unique value (feature)\n","data.groupby('Location').size()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vuo9nHVl6bRh"},"outputs":[],"source":["# plotting with multi indexing - groupby su più chiavi\n","\n","toplot = data.groupby(['marital', 'y']).size().unstack()\n","toplot.plot()\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vv9b-iEv6bRh"},"outputs":[],"source":["# NBB\n","# plotting tha same things as before, but a graph for each first key\n","toplot = data.groupby(['marital', 'y']).size()\n","\n","for i in toplot.index.levels[0]:\n","    toplot.loc[i].plot(kind='bar', title=i)\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FZwewOLI6bRh"},"outputs":[],"source":["# per capire se una classe influisce su quella di predizione ---- y è quella di predizione\n","toplot = dataset.groupby(['marital', 'y']).size()\n","total = dataset.groupby('y').size()\n","# automaticamente posso dividere per ogni indice\n","(toplot / total).unstack().plot(kind='bar')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YyfrHmzm6bRi"},"outputs":[],"source":["# plottare la media di una coppia di feature\n","toplot = dataset.groupby(['sex','G3']).size()# do .unstack() after, so we can divide by index\n","total = dataset.groupby('sex').size()\n","\n","(toplot / total).unstack().plot(kind='bar')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1lF-b7kd6bRi"},"outputs":[],"source":["# plot multiple curve on same graph\n","padri.plot(label='padri')\n","madri.plot(label='madri')\n","plt.xlabel('education')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"exSSwRZz6bRi"},"outputs":[],"source":["# per identificare una picco in un istogramma su una feature\n","data['satisfaction_level'].hist(bins=100) # guardo istogramma per vedere numero di istanze\n","data.groupby('satisfaction_level').size() # associo valore ad istanze\n","data[data['satisfaction_level'] <= 0.11] # seleziono istanze\n","# confronto con dati normali con describe()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rvozuxdV6bRi"},"outputs":[],"source":["# media e mediana di una feature\n","data['satisfaction_level'].describe()\n","\n","# usare describe per confrontare due dataset / colonne"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YG1UxMvV6bRi"},"outputs":[],"source":["hum = data[['Month', 'Location', 'Humidity9am', 'Humidity3pm']]\n","# per ogni coppia citta mese calcolo le temperature minime e massime calcolate al mattino e al pome\n","hum_max = hum.groupby(['Location', 'Month']).max()\n","hum_min = hum.groupby(['Location', 'Month']).min()\n","# qui cerco la massima/minima tra le due ----> mi fornisce quella giornaliera\n","hum_max = hum_max.max(axis=1)\n","hum_min = hum_min.min(axis=1)"]},{"cell_type":"markdown","metadata":{"id":"6a4aCb0J6bRj"},"source":["DATA TRANSFORMATION"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VBXAR0Po6bRj"},"outputs":[],"source":["# how to create a copy of a dataset\n","datanew = dataset.copy()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i92qV_LD6bRj"},"outputs":[],"source":["# drop rows with nan instances\n","data = data.dropna() # axis=1 drop columns\n","# fillna valuese\n","data = data.fillna(0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wkyHw6Xr6bRj"},"outputs":[],"source":["# drop columns\n","data = data.drop([coltoremove], axis=1)\n","# drop rows\n","dataset_n = dataset_n.drop(toremove.index)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n3XvYGE06bRj"},"outputs":[],"source":["#come si aggiungono colonne in modo idiomatico --- NB - viene messa alla fine\n","\n","# new attributo escursione termica\n","data['escursione'] = data['MaxTemp'] - data['MinTemp']\n","\n","# in alternativa va bene anche \n","tmp = pd.DataFrame(data['MaxTemp'] - data['MinTemp'], columns=['escursione'])\n","\n","#metto la colonna all'inizio -- si potrebbe anche concatenare (data[:, -1:],data[:, :-1])\n","data = tmp.join(data)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WxnIXgH96bRj"},"outputs":[],"source":["# rimpiazzare valori nominali con numeri\n","data = data.replace(['Yes', 'No'],[1,0])\n","# same ----> data.replace({'yes':1, 'no':0})\n","\n","#rimpiazzo solo una colonna\n","cities = data['Location'].unique()\n","data['Location'] = data['Location'].replace(cities, np.arange(len(cities)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HMM33Yqc6bRj"},"outputs":[],"source":["# scegliere solo un subset di colonne da rimpiazzare\n","data.columns[data.dtypes == 'object']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A-GrfdVF6bRk"},"outputs":[],"source":["# rimpiazzo tutte le colonne con valori numerici\n","for col in tomap.columns:\n","    uniquev = tomap[col].unique()\n","    tomap.loc[:, col] = tomap.loc[:, col].replace(uniquev, np.arange(len(uniquev))) # loc non è necessario ma non da warning"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rJGMBHU56bRk"},"outputs":[],"source":["# always check values after\n","data.dtypes\n","# if some values still not int\n","data['Location'].unique()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QLpgX38O6bRk"},"outputs":[],"source":["# dummies features su TUTTO il dataset ------ NB : ignora i valori float!!!!!! BUONO!\n","# NON IMPORTA SE I VALORI SONO STRINGHE ------ NON SERVE CONVERTIRE LE FEATURE IN NUMERI\n","data_dummy = pd.get_dummies(data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ejtHe5E_6bRk"},"outputs":[],"source":["# creare un nuovo dataframe con dummies features solo su determinate colonne\n","\n","new_data = data_numeric.copy()\n","\n","todummy = 'age_new' # colonne da dummizzare could be data.dtypes == 'object'\n","dummies = pd.get_dummies(data_numeric[todummy])\n","\n","new_data = new_data.drop(todummy, axis=1)\n","new_data = new_data.join(dummies)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OXqkmUO46bRk"},"outputs":[],"source":["# creare nuovi dataset\n","# new datasets from orginal dataset\n","cloudP = datini[datini['Cloud3pm'] < 0]\n","cloudT = datini[-(datini['Cloud3pm'] < 0)] # the sign - revert a boolean series"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9utsMfEh6bRk"},"outputs":[],"source":["# ricevere dati numeri da dataframe\n","data_numeric = data._get_numeric_data()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2dw0mRqr6bRk"},"outputs":[],"source":["# database basato solo su alcune colonne\n","data_color = data.loc[:, [0,3,9,14,15,17,20]]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yBU-611K6bRk"},"outputs":[],"source":["# eventuale renaming delle colonne\n","data_color = data_color.rename(columns={0:'p',\n","                                        3:'c1',\n","                                        9:'c2',\n","                                        14:'c3',\n","                                        15:'c4',\n","                                        17:'c5',\n","                                        20:'c6'})\n","\n","# se voglio rinominare tutte le colonne in con una lista\n","data_color.columns = ['p', 'c1', 'c2',...]"]},{"cell_type":"markdown","metadata":{"id":"FcLHNztc6bRl"},"source":["DATASET BALANCE"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"345Hvorn6bRl"},"outputs":[],"source":["# balance a data with resampling\n","# bigger rules or intermidiate value\n","from sklearn.utils import resample\n","\n","bigger = data_air[data_air['SIZE']==1] \n","smaller = data_air[data_air['SIZE']==3]\n","\n","# bilanciamo le classi \n","smaller = resample(smaller, replace=True, n_samples=5000) # can be also n_samples=len(bigger)\n","bigger = resample(bigger, replace=True, n_samples=5000) # non cessary if previous n_samples = len(bigger)\n","\n","data_bal = pd.concat([bigger, smaller])\n","data_bal.groupby('SIZE').size()"]},{"cell_type":"markdown","metadata":{"id":"6VFGujKE6bRl"},"source":["DATA PREPARATION"]},{"cell_type":"markdown","metadata":{"id":"2VSlQVNF6bRl"},"source":["NB posso spezzare i dati in mquesto modo se non mi è stata fornita nessuna specifica"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wIgN0pg76bRl"},"outputs":[],"source":["# nel caso la colonna di classificazione non sia in fondo possiamo usare questa notazione\n","X = data.drop('Cloud3pm', axis=1)\n","y = data['Cloud3pm']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d9hxAte46bRl"},"outputs":[],"source":["# dividere il dataset in un N intervalli \n","# ---> ritorna array contenente indice di appartenenza ad un bin\n","interval = pd.cut(data_numeric['age'], bins=3, labels=False) "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1a805-UY6bRl"},"outputs":[],"source":["# nel caso dobbiamo dividere per ogni classe di size\n","# NBBBB-----> automaticamente con train_test_split() prendendo i valori a random\n","# ----------> le proprietà dovrebbero rimane quasi rispettate (ma non sarà perfetto)\n","\n","index1 = data_bal['SIZE'] == 1\n","index3 = data_bal['SIZE'] == 3\n","index5 = data_bal['SIZE'] == 5\n","\n","X_1 = data_bal[index1].drop('SIZE', axis=1)\n","y_1 = data_bal.loc[index1, 'SIZE']\n","\n","X_3 = data_bal[index3].drop('SIZE', axis=1)\n","y_3 = data_bal.loc[index3, 'SIZE']\n","\n","X_5 = data_bal[index5].drop('SIZE', axis=1)\n","y_5 = data_bal.loc[index5, 'SIZE']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"407Jo5iB6bRl"},"outputs":[],"source":["# andiamo poi ad unire le classi\n","fraction = 0.25\n","\n","X_1train, X_1test, y_1train, y_1test = train_test_split(X_1, y_1, test_size=fraction)\n","X_3train, X_3test, y_3train, y_3test = train_test_split(X_3, y_3, test_size=fraction)\n","X_5train, X_5test, y_5train, y_5test = train_test_split(X_5, y_5, test_size=fraction)\n","\n","X_train = pd.concat([X_5train, X_3train, X_1train])\n","X_test = pd.concat([X_5test, X_3test, X_1test])\n","\n","y_train = pd.concat([y_5train, y_3train, y_1train])\n","y_test = pd.concat([y_5test, y_3test, y_1test])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4J4rvhjZ6bRl"},"outputs":[],"source":["fraction = 0.2\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=fraction)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qu1pM3p-6bRm"},"outputs":[],"source":["# convert y to ndarray -----> solo se fatto senza train_test_split()\n","\n","y_train = np.ravel(y_train)\n","y = np.ravel(y)"]},{"cell_type":"markdown","source":["# EXAM QUESTIONS"],"metadata":{"id":"j2UCD4wpIAcj"}},{"cell_type":"markdown","source":["## EXAM 1"],"metadata":{"id":"ylZ6GaVJ0nE7"}},{"cell_type":"markdown","source":["#### Dividere i valori assunti dalla variabile AGE in 10 gruppi. Verificare se per ogni gruppo sono presenti un numero simile di pazienti rispetto la classe da predire. Verificare inoltre la distribuzione della classe da predire rispetto al genere (SEX)."],"metadata":{"id":"jzuDIL_5IEun"}},{"cell_type":"code","source":["# Copio per evitare inconvenienti\n","ds_binnedage = dataset.copy()\n","# Divido la colonna AGE tramite pd.cut()\n","ds_binnedage['AGE'] = pd.cut(ds_binnedage['AGE'],10)\n","# Controllo la divisione\n","ds_binnedage['AGE'].value_counts()\n","# Plotto la distribuzuibe\n","(ds_binnedage.groupby(['AGE','SOURCE']).size().unstack().plot.bar()\n","# Distribuzione classe ripsetto ad una colonna\n"," dataset.groupby(['SEX','SOURCE']).size().unstack().plot.bar()\n"," # Se vogliamo normalizzare\n"," (dataset.groupby(['SEX','SOURCE']).size()/dataset.groupby(['SEX']).size()).unstack().plot.bar()"],"metadata":{"id":"aUeiICHDIDIa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Verificare se è vero che le donne si ammalano meno degli uomini. Rappresentare graficamente se possibile quanto emerge dai dati.(punti 2)"],"metadata":{"id":"Yi1-vFzrKjHE"}},{"cell_type":"code","source":["# Lo abbiamo già verificato tramite l'ultimo plot, ci basta dunque togliere il \n","# plotting per avere le percentuali\n","(dataset.groupby(['SEX','SOURCE']).size()/dataset.groupby(['SEX']).size()).unstack()"],"metadata":{"id":"wXjBSngLKkgg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Realizzare una pivot_table in cui rappresentare come si comporta la classe da predire rispetto i 10 gruppi di AGE (sulle righe), e il SEX (sulle colonne)"],"metadata":{"id":"ffbjae6xMeEp"}},{"cell_type":"code","source":["# Per realizzare una pivot dobbiamo indicare cosa vogliamo in verticale e cosa\n","# in orizzontale, in particolare ci interessa vedere la classe da preddire \n","# quindi specifichiamo ['SOURCE']\n","ds_binnedage.pivot_table(index='AGE',columns='SEX')['SOURCE']"],"metadata":{"id":"Ukn3sBGCMgAC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Si vuole predire il valore di SOURCE sulla base degli attributi presenti nel dataset. Ricaricare il dataset originale, rendere gli attributi numerici, e dividerlo in modo che 2/3 degli elementi siano contenuti in un nuovo dataset “train” e 1/3 nel dataset “test”. Allenare il train con il modello Decision Tree e valutare l’accuracy ottenuta calcolata sia sul dataset train sia sul dataset test. Confrontare i risultati ottenuti con quelli ottenuti con una predizione basata sul modello Logistic Regression (ignorare eventuali warning). Effettuare alcune considerazioni sui risultati ottenuti, tenendo in considerazione anche l’analisi della confusion matrix e la predizione effettuata da un dummy classifier."],"metadata":{"id":"X9qQZCWfyaSF"}},{"cell_type":"code","source":["# Dobbiamo rendere gli attributi numerici, in questo caso solamente 'SEX'\n","# richiede modifiche, possiamo fare in questo modo dato che il dataset si\n","# presenta in un certo modo\n","ds['SEX'] = ds['SEX'].replace({'F': 0, 'M': 1})\n","\n","# Una soluzione diversa può essere quella di utilizzare il LabelEncoder di \n","# sklearn\n","from sklearn import preprocessing\n","le = preprocessing.LabelEncoder()\n","le.fit(ds['SEX'])\n","ds['SEX'] = le.transform(ds['SEX'])"],"metadata":{"id":"eEIp38HoyclD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#eventuale comando per ignorare i warnings\n","#import warnings\n","#warnings.filterwarnings('ignore')"],"metadata":{"id":"9CGcG8RZ036H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Quando si tratta di classificazione dobbiamo sempre guardare quale sia la\n","# classe da predirre e seprararla dal dataset (in questo caso 'SOURCE')\n","X = ds.drop(columns='SOURCE')\n","y = ds['SOURCE']"],"metadata":{"id":"6TWL6XXt06my"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Classification pipeline\n","X_train, X_test, y_train, y_test =train_test_split(X,y,\n","                                                   train_size = 2/3,\n","                                                   test_size=1/3,\n","                                                   random_state=0,\n","                                                   stratify=ds['SOURCE'])\n","\n","modeldt = DecisionTreeClassifier()\n","modellr = LogisticRegression()\n","model_dummy = DummyClassifier(strategy = 'prior')\n","\n","print(\"\\nVALUTAZIONE MODELLO: DECISION TREE \")\n","\n","modeldt.fit(X_train,y_train)\n","\n","print(\"\\nRisultati su train\")\n","predict = modeldt.predict(X_train)\n","\n","plot_confusion_matrix(modeldt, X_train, y_train, normalize='true')  \n","plt.show() \n","print(\"\\nAccuracy train:\", accuracy_score(y_train, predict),\"\\n\")\n","\n","print(\"\\nRisultati su test\")\n","predict = modeldt.predict(X_test)\n","\n","plot_confusion_matrix(modeldt, X_test, y_test, normalize='true')  \n","plt.show() \n","print(\"\\nAccuracy test:\", accuracy_score(y_test, predict),\"\\n\")\n","\n","\n","print(\"\\nVALUTAZIONE MODELLO: LOGISTIC REGRESSION \")\n","\n","modellr.fit(X_train,y_train)\n","\n","print(\"\\nRisultati su train\")\n","predict = modellr.predict(X_train)\n","\n","plot_confusion_matrix(modellr, X_train, y_train, normalize='true')  \n","plt.show() \n","print(\"\\nAccuracy train:\", accuracy_score(y_train, predict),\"\\n\")\n","\n","print(\"\\nRisultati su test\")\n","predict = modellr.predict(X_test)\n","\n","plot_confusion_matrix(modellr, X_test, y_test, normalize='true')  \n","plt.show() \n","print(\"\\nAccuracy test:\", accuracy_score(y_test, predict),\"\\n\")\n","\n","\n","print(\"\\nVALUTAZIONE MODELLO: DUMMY CLASSIFIER \")\n","\n","model_dummy.fit(X_train,y_train)\n","\n","print(\"\\nRisultati su train\")\n","predict = model_dummy.predict(X_train)\n","\n","plot_confusion_matrix(model_dummy, X_train, y_train, normalize='true')  \n","plt.show() \n","print(\"\\nAccuracy train:\", accuracy_score(y_train, predict),\"\\n\")\n","\n","print(\"\\nRisultati su test\")\n","predict = model_dummy.predict(X_test)\n","\n","plot_confusion_matrix(model_dummy, X_test, y_test, normalize='true')  \n","plt.show() \n","print(\"\\nAccuracy test:\", accuracy_score(y_test, predict),\"\\n\")\n"],"metadata":{"id":"B_6Yy_Kr69_8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Se ci viene chiesta la cross fold validation\n","num_fold = 10\n","\n","modeldt = DecisionTreeClassifier()\n","modellr = LogisticRegression()\n","model_dummy = DummyClassifier(strategy = 'prior')\n","\n","print(\"\\nVALUTAZIONE MODELLO: DECISION TREE \")\n","\n","modeldt.fit(X_train,y_train)\n","\n","cv_results = cross_val_score(modeldt, X, y, cv=num_fold, scoring='accuracy')\n","print(\"Accuracy: %0.2f (+/- %0.2f)\" % (cv_results.mean(), cv_results.std() * 2))\n","\n","\n","print(\"\\nVALUTAZIONE MODELLO: LOGISTIC REGRESSION \")\n","\n","modellr.fit(X_train,y_train)\n","\n","cv_results = cross_val_score(modellr, X, y, cv=num_fold, scoring='accuracy')\n","print(\"Accuracy: %0.2f (+/- %0.2f)\" % (cv_results.mean(), cv_results.std() * 2))\n","\n","\n","print(\"\\nVALUTAZIONE MODELLO: DUMMY CLASSIFIER \")\n","\n","model_dummy.fit(X_train,y_train)\n","\n","cv_results = cross_val_score(model_dummy, X, y, cv=num_fold, scoring='accuracy')\n","print(\"Accuracy: %0.2f (+/- %0.2f)\" % (cv_results.mean(), cv_results.std() * 2))"],"metadata":{"id":"0opGy9Yp7qq9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Trovare i parametri migliori del classificatore decision tree. Agire sui parametri criterion, max_features e min_samples_split. Verificare se l’accuratezza che si ottiene con la nuova configurazione supera quella standard ottenuta al punto 1"],"metadata":{"id":"8jAeY5Tl8bPc"}},{"cell_type":"code","source":["# Per trovare i parametri migliori dobbiamo utilizzare il GridSearch\n","tuned_parameters = [{'max_features': ['auto', 'sqrt', 'log2'],\n","                     'criterion': ['gini', 'entropy'], \n","                    'min_samples_split': [2,3,4,5,10]\n","                     }]\n","\n","scores = ['accuracy']\n","\n","for score in scores:\n","    print(\"# Tuning hyper-parameters for %s\" % score)\n","    print()\n","\n","    clf = GridSearchCV(modelGS, tuned_parameters, cv=num_fold,\n","                       scoring= score)\n","    clf.fit(X_train, y_train)\n","\n","    print(\"Best parameters set found on development set:\")\n","    print()\n","    print(clf.best_params_)\n","    print()\n","    print(\"Grid scores on development set:\")\n","    print()\n","    means = clf.cv_results_['mean_test_score']\n","    stds = clf.cv_results_['std_test_score']\n","    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n","        print(\"%0.3f (+/-%0.03f) for %r\"\n","              % (mean, std * 2, params))\n","    print()\n","\n","    print(\"Detailed classification report:\")\n","    print()\n","    print(\"The model is trained on the full development set.\")\n","    print(\"The scores are computed on the full evaluation set.\")\n","    print()\n","    y_true, y_pred = y_test, clf.predict(X_test)\n","    print(classification_report(y_true, y_pred))\n","\n","plot_confusion_matrix(clf, X_test, y_test, normalize='true')  \n","plt.show() \n","print(\"\\nAccuracy test:\", accuracy_score(y_test, predict),\"\\n\")"],"metadata":{"id":"yVRfJKgQ7ySZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Introdurre una discretizzazione degli attributi AGE e THROMBOCYTE, e utilizzare la funzione MaxAbsScaler (oppure MinMax) per scalare i valori del dataset tra 0 e 1 e confrontare se l’accuratezza ottenuta con il Decision Tree Classifier e con la Logistic Regression migliora "],"metadata":{"id":"VVV7-ufQ8X3v"}},{"cell_type":"code","source":["# Discretizzazione di N attributi\n","to_bins=['AGE','THROMBOCYTE']\n","\n","col_transformers = ColumnTransformer(transformers=[('binning', KBinsDiscretizer(encode='onehot'), to_bins)],\n","                                      remainder='passthrough')\n","\n","preprocessing = Pipeline(steps=[('col_transformers', col_transformers),\n","                                ('maxAbs', MaxAbsScaler())])\n","\n","modeldt = DecisionTreeClassifier(criterion ='gini', max_features = 'sqrt', min_samples_split = 10)\n","modellr = LogisticRegression()\n","\n","my_pipelinedt = Pipeline(steps=[('preprocessing', preprocessing),\n","                              ('model', modeldt)])\n","\n","my_pipelinelr = Pipeline(steps=[('preprocessing', preprocessing),\n","                              ('model', modellr)])\n","\n","\n","print(\"\\nVALUTAZIONE MODELLO: DECISION TREE \")\n","\n","my_pipelinedt.fit(X_train,y_train)\n","\n","cv_results = cross_val_score(my_pipelinedt, X, y, cv=num_fold, scoring='accuracy')\n","print(\"Accuracy: %0.2f (+/- %0.2f)\" % (cv_results.mean(), cv_results.std() * 2))\n","\n","plot_confusion_matrix(my_pipelinedt, X_test, y_test, normalize='true')  \n","plt.show() \n","\n","print(\"\\nVALUTAZIONE MODELLO: LOGISTIC REGRESSION \")\n","\n","my_pipelinelr.fit(X_train,y_train)\n","\n","cv_results = cross_val_score(my_pipelinelr, X, y, cv=num_fold, scoring='accuracy')\n","print(\"Accuracy: %0.2f (+/- %0.2f)\" % (cv_results.mean(), cv_results.std() * 2))\n","\n","plot_confusion_matrix(my_pipelinelr, X_test, y_test, normalize='true')  \n","plt.show() "],"metadata":{"id":"QIbytdU28IK8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Creare una pipeline in cui il valore di AGE sia discretizzato in 4 intervalli, il valore di THROMBOCYTE sia discretizzato in 10 intervalli e poi il dataset venga ricondotto a valori nell’intervallo (0,1) e normalizzato con la funzione Normalizer. Si applichi poi un modello DecisionTree."],"metadata":{"id":"10PtpE7N8T_8"}},{"cell_type":"code","source":["# Pipeline di questo esame\n","col_transformers = ColumnTransformer(transformers=[('bins_age', KBinsDiscretizer(n_bins=4,encode='onehot'), ['AGE']),\n","                                                   ('bins_THROMBOCYTE', KBinsDiscretizer(n_bins=10,encode='onehot'), ['THROMBOCYTE'])],\n","                                      remainder='passthrough')\n","\n","preprocessing = Pipeline(steps=[('col_transformers', col_transformers),\n","                                ('minmax', MinMaxScaler(feature_range=(0, 1))),\n","                                ('normalizer',Normalizer())])\n","\n","modeldt = DecisionTreeClassifier(criterion ='gini', max_features = 'sqrt', min_samples_split = 10)\n","\n","my_pipelinedt = Pipeline(steps=[('preprocessing', preprocessing),\n","                              ('model', modeldt)])\n","\n","\n","print(\"\\nVALUTAZIONE MODELLO: DECISION TREE \")\n","\n","my_pipelinedt.fit(X_train,y_train)\n","\n","cv_results = cross_val_score(my_pipelinedt, X, y, cv=num_fold, scoring='accuracy')\n","print(\"Accuracy: %0.2f (+/- %0.2f)\" % (cv_results.mean(), cv_results.std() * 2))\n","\n","plot_confusion_matrix(my_pipelinedt, X_test, y_test, normalize='true')  \n","plt.show() "],"metadata":{"id":"Pnre1KNN8QHW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Applicare una funzione per l’ottimizzazione dei parametri (sia al DecisionTree sia alla regressione lineare, su parametri a piacere o dell’algoritmo o della normalizzazione) e verificare se l’accuratezza migliora."],"metadata":{"id":"gJ8TPwUN8nc0"}},{"cell_type":"code","source":["#PIPELINE DECISION TREE\n","col_transformers = ColumnTransformer(transformers=[('bins_age', KBinsDiscretizer(n_bins=4,encode='onehot'), ['AGE']),\n","                                                   ('bins_THROMBOCYTE', KBinsDiscretizer(n_bins=10,encode='onehot'), ['THROMBOCYTE'])],\n","                                      remainder='passthrough')\n","\n","preprocessing = Pipeline(steps=[('col_transformers', col_transformers),\n","                                ('minmax', MinMaxScaler(feature_range=(0, 1))),\n","                                ('normalizer',Normalizer())])\n","\n","modeldt = DecisionTreeClassifier()\n","\n","my_pipelinedt = Pipeline(steps=[('preprocessing', preprocessing),\n","                              ('modeldt', modeldt)])\n","\n","parameters = {\n","    'modeldt__max_features': ['auto', 'sqrt'],\n","    'modeldt__min_samples_split': [5,10],\n","    'preprocessing__col_transformers__bins_age__n_bins': [4,10],\n","    'preprocessing__col_transformers__bins_THROMBOCYTE__n_bins': [8,10],\n","    'preprocessing__normalizer__norm':['l1','l2']\n","}\n","\n","gs_clf = GridSearchCV(my_pipelinedt, parameters,  cv=5, n_jobs=-1)\n","gs_clf.fit(X_train, y_train)\n","\n","gs_clf.best_params_\n","\n","print(\"\\n\",gs_clf.best_params_)\n","\n","my_pipelinedt.set_params(**gs_clf.best_params_)\n","# Preprocessing of training data, fit model \n","my_pipelinedt.fit(X_train, y_train)\n","\n","# Preprocessing of validation data, get predictions\n","preds = my_pipelinedt.predict(X_test)\n","\n","# Evaluate the model\n","score = accuracy_score(y_test, preds)\n","print('\\nAccuracy Score on test:', score)\n","print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, preds))"],"metadata":{"id":"ZYdSdFLI8oW-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# PIPELINE REGRESSOR\n","col_transformers = ColumnTransformer(transformers=[('bins_age', KBinsDiscretizer(n_bins=4,encode='onehot'), ['AGE']),\n","                                                   ('bins_THROMBOCYTE', KBinsDiscretizer(n_bins=10,encode='onehot'), ['THROMBOCYTE'])],\n","                                      remainder='passthrough')\n","\n","preprocessing = Pipeline(steps=[('col_transformers', col_transformers),\n","                                ('minmax', MinMaxScaler(feature_range=(0, 1))),\n","                                ('normalizer',Normalizer())])\n","\n","modelreg = LinearRegression()\n","\n","my_pipelinereg = Pipeline(steps=[('preprocessing', preprocessing),\n","                              ('modelreg', modelreg)])\n","\n","parameters = {\n","    'modelreg__fit_intercept': ['False', 'True'],\n","    'preprocessing__col_transformers__bins_age__n_bins': [4,10],\n","    'preprocessing__col_transformers__bins_THROMBOCYTE__n_bins': [8,10],\n","    'preprocessing__normalizer__norm':['l1','l2']\n","}\n","\n","gs_clf = GridSearchCV(my_pipelinereg, parameters,  cv=5, n_jobs=-1)\n","gs_clf.fit(X_train, y_train)\n","\n","gs_clf.best_params_\n","\n","print(\"\\n\",gs_clf.best_params_)\n","\n","my_pipelinereg.set_params(**gs_clf.best_params_)\n","# Preprocessing of training data, fit model \n","my_pipelinereg.fit(X_train, y_train)\n","\n","# Preprocessing of validation data, get predictions\n","np.round(np.clip(my_pipelinereg.predict(X_test), 0,1))\n","\n","# Evaluate the model\n","score = accuracy_score(y_test, preds)\n","print('\\nAccuracy Score on test:', score)"],"metadata":{"id":"tg5G5oKu8xVy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## EXAM 2"],"metadata":{"id":"-mtfCauu0pKj"}},{"cell_type":"markdown","source":["#### Le rilevazioni con pressione e umidità uguale a 0 sono irreali. Quante sono queste rilevazioni? Eliminarle dal dataset"],"metadata":{"id":"uXqEOZ3n0ycC"}},{"cell_type":"code","source":["# Trovo le righe con queste condizioni\n","df[np.logical_or(df.pressure == 0, df.humidity == 0)].shape[0]\n","\n","# E le elimino\n","index = df[np.logical_or(df.pressure == 0, df.humidity == 0)].index\n","data = df.drop(index)"],"metadata":{"id":"uGLoqvsf0qpu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Analizzare la temperatura massima rilevata. Valutare se la distribuzione dei valori assume un andamento simile a una gaussiana. Considerare poi le rilevazioni che si collocano all’interno del 5% delle temperature più alte. Le città sono equamente presenti in quella fascia di rilevazioni? Come è il tempo complessivo nei giorni in cui la temperatura massima è in quella fascia per ogni città?"],"metadata":{"id":"uV9sSdHj1qcm"}},{"cell_type":"code","source":["# Isolo l'attributo che mi viene chiesto e ne plotto la distribuzione\n","max_t = data.temp_max\n","sns.distplot(max_t, color='k')"],"metadata":{"id":"7PAlHjOb1rfC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Per considerare le rilevazioni in una certa percentuale\n","top_5t = data[max_t >= max_t.quantile(0.95)]\n","top_5t.groupby('city_name').size()"],"metadata":{"id":"oZFtOW1V2TIR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# La terza domanda chiede lo stato di una colonna in funzione di un'altra\n","top_5t.groupby(['city_name', 'weather_main']).size().unstack().plot.bar()\n","# Importante quando vogliamo plottare più cose dopo un groupby sempre mettere \n","# unstack() altrimenti avrò molte più colonne sul grafico"],"metadata":{"id":"lCXeJZ1V3b2q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Utilizzare la funzione Normalizer per normalizzare i valori del dataset e confrontare se l’accuratezza ottenuta con il Decision Tree Classifier migliora "],"metadata":{"id":"3ZNhMH6w_QQN"}},{"cell_type":"code","source":["from sklearn.preprocessing import Normalizer\n","\n","X = dataset.drop(columns='weather_main')\n","y = dataset['weather_main']\n","\n","normaliz = Normalizer()\n","X_norm = normaliz.fit_transform(X)\n","\n","model = DecisionTreeClassifier()\n","\n","cv_results = cross_val_score(model, X_norm, y, cv=10, scoring='accuracy')\n","print(\"Results:\\n\",cv_results,\"\\nMean Accuracy:\",cv_results.mean(), \"\\nAccuracy STD: \",cv_results.std())"],"metadata":{"id":"HY3P85fm_Rk1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Creare una pipeline con trasformatori PCA (si scelgano 5 attributi) e poi Normalizer. Si usi come modello il Decision Tree Classifier (punti 2) [2 punti ulteriori se gli attributi della PCA sono aggiunti agli attributi del dataset]"],"metadata":{"id":"izm6DZ9L_gYE"}},{"cell_type":"code","source":["from sklearn.pipeline import Pipeline\n","from sklearn.pipeline import FeatureUnion\n","from sklearn.preprocessing import FunctionTransformer\n","from sklearn.preprocessing import Normalizer\n","from sklearn.decomposition import PCA\n","\n","\n","X = dataset.drop(columns='weather_main')\n","y = dataset['weather_main']\n","\n","\n","pca = PCA(n_components=5)\n","\n","def identity_func(X):\n","  return X\n","\n","# Il function transformer serve per aggiungere al dataset originale\n","combined = FeatureUnion([(\"pca\", pca),('passtrough',FunctionTransformer(identity_func,validate=False))])\n","#creo 5 colonne con pca unite al dataset originale, tramite una funzione identità con FunctionTransformer\n","\n","norm = Normalizer()\n","\n","model = DecisionTreeClassifier()\n","\n","# Bundle preprocessing and modeling code in a pipeline\n","my_pipeline = Pipeline(steps=[('combined', combined),\n","                              ('normalizer',norm),\n","                              ('model', model)\n","                             ], verbose = True)\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y,\n","                                                    test_size=1/3,\n","                                                    train_size=2/3 ,\n","                                                    stratify=dataset['weather_main'],\n","                                                    random_state=0)\n","\n","# Preprocessing of training data, fit model \n","my_pipeline.fit(X_train, y_train)\n","\n","# Preprocessing of validation data, get predictions\n","preds = my_pipeline.predict(X_test)\n","\n","# Evaluate the model on test\n","score = accuracy_score(y_test, preds)\n","print('\\nAccuracy Score:', score,\"\\n\")\n","\n","plot_confusion_matrix(my_pipeline, X_test, y_test, normalize='true')\n","plt.show() \n","\n","# Evaluate the model on train\n","preds = my_pipeline.predict(X_train)\n","\n","score = accuracy_score(y_train, preds)\n","print('\\nAccuracy Score:', score,\"\\n\")\n","\n","plot_confusion_matrix(my_pipeline, X_train, y_train, normalize='true')\n","plt.show()"],"metadata":{"id":"Xb5PDmSX_hYs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Utilizzare la funzione di gridSearchCV sulla pipeline per modificare il numero di attributi selezionati dalla PCA e alcuni parametri a piacere del classificatore. Verificare se l’accuratezza che si ottiene con la nuova configurazione supera quella standard ottenuta al punto 1"],"metadata":{"id":"Ay2Izx0WDvjk"}},{"cell_type":"code","source":["X = dataset.drop(columns='weather_main')\n","y = dataset['weather_main']\n","\n","\n","pca = PCA(n_components=5)\n","\n","def identity_func(X):\n","  return X\n","\n","combined = FeatureUnion([(\"pca\", pca),('passtrough',FunctionTransformer(identity_func,validate=False))])\n","#creo 5 colonne con pca unite al dataset originale, tramite una funzione identità con FunctionTransformer\n","\n","norm = Normalizer()\n","\n","model = DecisionTreeClassifier()\n","\n","# Bundle preprocessing and modeling code in a pipeline\n","my_pipeline = Pipeline(steps=[('combined', combined),\n","                              ('normalizer',norm),\n","                              ('model', model)\n","                             ], verbose = True)\n","\n","from sklearn.model_selection import GridSearchCV\n","\n","# Parto dal nome dell'oggetto 'combined', proseguo a quale pezzo della pipeline 'pca'\n","# infine specifico quale parametro voglio cercare di ottimizzare\n","parameters = {\n","    'combined__pca__n_components':[2,3,5],\n","    'model__max_features': ['auto', 'sqrt', 'log2'],\n","    'model__max_depth': [4,6,10],\n","}\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y,\n","                                                    test_size=1/3,\n","                                                    train_size=2/3 ,\n","                                                    stratify=dataset['weather_main'],\n","                                                    random_state=0)\n","\n","gs_clf = GridSearchCV(my_pipeline, parameters,  cv=5, n_jobs=-1)\n","gs_clf.fit(X_train, y_train)\n","\n","gs_clf.best_params_\n","\n","my_pipeline.set_params(**gs_clf.best_params_)\n","# Preprocessing of training data, fit model \n","my_pipeline.fit(X_train, y_train)\n","\n","# Preprocessing of validation data, get predictions\n","preds = my_pipeline.predict(X_test)\n","\n","# Evaluate the model on test\n","score = accuracy_score(y_test, preds)\n","print('Accuracy Score on test:', score)\n","\n","# Evaluate the model train\n","score = accuracy_score(y_train, my_pipeline.predict(X_train))\n","print('Accuracy Score on train:', score)\n","\n","# Parametri migliori scelti\n","print(gs_clf.best_params_)\n","\n","# Evaluate the model on test\n","score = accuracy_score(y_test, preds)\n","print('\\nAccuracy Score:', score,\"\\n\")\n","\n","plot_confusion_matrix(my_pipeline, X_test, y_test, normalize='true')\n","plt.show() \n","\n","# Evaluate the model on train\n","preds = my_pipeline.predict(X_train)\n","\n","score = accuracy_score(y_train, preds)\n","print('\\nAccuracy Score:', score,\"\\n\")\n","\n","plot_confusion_matrix(my_pipeline, X_train, y_train, normalize='true')\n","plt.show()"],"metadata":{"id":"VG8QtBnDDylZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## EXAM 3"],"metadata":{"id":"-cKeL_HMWlvf"}},{"cell_type":"markdown","source":["#### Creare una pipeline in cui il valore di ram sia discretizzato in 4 intervalli, il valore di battery_power sia discretizzato in 10 intervalli e poi il dataset venga ricondotto a valori nell’intervallo (0,1) e normalizzato con la funzione Normalizer. Si applichi poi un modello DecisionTree."],"metadata":{"id":"IferGU7sWnNu"}},{"cell_type":"code","source":["# Selezioni quali sono le colonne che non devono essere toccate\n","# Includo ovviamente anche la variabile da predirre\n","untransformed_cols = []\n","for col in df.columns:\n","  if col not in ['ram', 'battery_power', 'price_range']:\n","    untransformed_cols.append(col)\n","\n","col_transformers = ColumnTransformer(transformers=[('ram', KBinsDiscretizer(n_bins=4, encode='ordinal'), ['ram']),\n","                                                   ('batt_pw', KBinsDiscretizer(n_bins=10, encode='ordinal'), ['battery_power']),\n","                                                   ('others', 'passthrough', untransformed_cols)])\n","\n","# Da qui applico gli step come da consegna\n","preprocessing = Pipeline(steps=[('col_transformers', col_transformers),\n","                                ('maxAbs', MaxAbsScaler()),\n","                                ('normalizer', Normalizer())])\n","\n","model = DecisionTreeClassifier()\n","\n","# Creo una seconda pipeline contente anche il modello\n","my_pipeline = Pipeline(steps=[('preprocessing', preprocessing),\n","                              ('model', model)])\n","\n","X = df.drop(columns='price_range')\n","y = df['price_range']\n","\n","# Splitto e fitto la pipeline\n","X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=1/4,random_state=0)\n","my_pipeline.fit(X_train,y_train)\n","\n","# Matrice di confusione ed accuracy sul test set\n","\n","predict = my_pipeline.predict(X_test)\n","\n","print(\"Test Set Results\")\n","print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, predict))\n","plot_confusion_matrix(my_pipeline, X_test, y_test, normalize='true')\n","plt.show() \n","print(\"\\nAccuracy:\", accuracy_score(y_test, predict),\"\\n\")\n","\n","# Matrice di confusione ed accuracy sul train set\n","\n","predict = my_pipeline.predict(X_train)\n","\n","print(\"Train Set Results\")\n","print(\"Confusion Matrix:\\n\", confusion_matrix(y_train, predict))\n","plot_confusion_matrix(my_pipeline, X_train, y_train, normalize='true')\n","plt.show() \n","print(\"\\nAccuracy:\", accuracy_score(y_train, predict),\"\\n\")"],"metadata":{"id":"H0r2n13JWpTj"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"},"colab":{"provenance":[{"file_id":"1xQWwJlQd9Vm3I0TQvYimIs7wEzbelHgJ","timestamp":1662738132432}]}},"nbformat":4,"nbformat_minor":0}